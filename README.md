## Towards Few-Call Model Stealing via Active Self-Paced Knowledge Distillation and Diffusion-Based Image Generation (published in Artificial Intelligence Review)  - Official Implementation

### Description
We propose to copy black-box classification models without having access to the original training data, the architecture, and the weights of the model, i.e. the model is only exposed through an inference API. More specifically, we can only observe the (soft or hard) labels for some image samples passed as input to the model. Furthermore, we consider an additional constraint limiting the number of model calls, mostly focusing our research on few-call model stealing. In order to solve the model extraction task given the applied restrictions, we propose the following framework. As training data, we create a synthetic data set (called proxy data set) by leveraging the ability of diffusion models to generate realistic and diverse images. Given a maximum number of allowed API calls, we pass the respective number of samples through the black-box model to collect labels. Finally, we distill the knowledge of the black-box teacher (attacked model) into a student model (copy of the attacked model), harnessing both labeled and unlabeled data generated by the diffusion model. We employ a novel active self-paced learning framework to make the most of the proxy data during distillation. Our empirical results on three data sets confirm the superiority of our framework over four state-of-the-art methods in the few-call model extraction scenario. 

### Citation

If you use this code in your research, please cite the corresponding paper:

Vlad Hondru, Radu Tudor Ionescu. Towards few-call model stealing via active self-paced knowledge distillation and diffusion-based image generation. Artificial Intelligence Review 58, no. 8 (2025): 1-25.

Bibtex:
```
@article{Hondru-AIR-2025,
  title={Towards few-call model stealing via active self-paced knowledge distillation and diffusion-based image generation},
  author={Hondru, Vlad and Ionescu, Radu Tudor},
  journal={Artificial Intelligence Review},
  volume={58},
  number={8},
  pages={1--25},
  year={2025},
  publisher={Springer}
}
```

### Setup
Install requirements

``` pip install -r requirements.txt ```

If you want access to our pretrained models (teachers - trained on the true datasets, and students - trained on TinyImagenet200), please download them using:
 ``` bash download_checkpoints.sh ```


### Models
We provide the implementation for our method from the paper, along with the models we used for the experiments. These are:
Students:
    - HalfAlexNet
    - Resnet18
Teachers:
    - AlexNet
    - Resnet18
    - Resnet50

### Experiments can then be run, as follows:
1. Create the proxy dataset using any diffusion model.
2. Add the images in a follder called "images_generated_DATASET_NAME" (you can change DATASET_NAME as you please). The folder structure should be: 2 folders (train and valid) that contains subfolder named after the class with the respective images, as well as 2 json files that contain the labels.
3. Run the following command:

```python start_experiment.py --epochs 200 --batch_size 64 --lr 0.001 --step_size 20 --dataset DATASET_NAME --student resnet --teacher alexnet --use_soft_labels True --use_active_learning True --use_og_labels True --distance cosine --use_all_data True ```

### Acknowledgements
This research is supported by the project “Romanian Hub for Artificial Intelligence - HRIA”, Smart Growth, Digitization and Financial Instruments Program, 2021-2027, MySMIS no. 334906.

Our code is based on "Black-Box Ripper: Copying black-box models using generative evolutionary algorithms". We forked from their repository, which is available here: https://github.com/antoniobarbalau/black-box-ripper.
